{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Loading data from csv to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnk1 = sc.textFile(\"/home/anil/Anil_Created_Docs/01.02.BID DATA/PySPark/anil_trading/data/6440633_01042019_06032020.csv\")\n",
    "bnk1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnk3 = bnk1.zipWithIndex().filter(lambda x : x[1] > 0).map(lambda x : x[0])\n",
    "bnk3.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnk2 = bnk1.map(lambda x : x.split(\",\"))\n",
    "bnk2.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from csv to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField('Date', StringType(), True)\n",
    "               , StructField('Narration', StringType(), True)\n",
    "               , StructField('Chq_Ref_No', StringType(), True)\n",
    "               , StructField('Value_Date', StringType(), True)\n",
    "               , StructField('Withdrawl_Amt', IntegerType(), True)\n",
    "               , StructField('Deposit_Amt', IntegerType(), True)\n",
    "               ,  StructField('Closing_Bal', IntegerType(), True)\n",
    "              ,  StructField('Closing_Bal1', IntegerType(), True)]\n",
    "final_struc = StructType(fields=data_schema)\n",
    "df = spark.read.csv('/home/anil/Anil_Created_Docs/01.02.BID DATA/PySPark/anil_trading/data/6440633_01042019_06032020.csv', sep=\",\",header=True \n",
    "                    ,inferSchema=True\n",
    "                    #, schema=final_struc\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.select(\"Date\",\"Closing Balance\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr()\n",
    "#https://stackoverflow.com/questions/34803855/pyspark-dataframe-udf-on-text-column?rq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"Narration\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\"DEPOSITORY CHARGES\",\"NET PI TO HSL\",\"NET PO FROM HSL\",\"IRCTC\",\"APSRTC\",\"CAPITALISED\",\"ATW-\",\"SALARY CREDIT\"]\n",
    "\n",
    "for x in range(len(pattern)):\n",
    "    print(pattern[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "import re\n",
    "\n",
    "\n",
    "def findTxnCategory(value):\n",
    "    pattern_list = [\"DEPOSITORY CHARGES\",\"NET PI TO HSL\",\"NET PO FROM HSL\",\"IRCTC\",\"APSRTC\",\"CAPITALISED\"\n",
    "                    ,\"ATW-\",\"SALARY CREDIT\",\"DELHI PUBLIC SCHOOL\",\"SBI CARDS\"]\n",
    "    for x in range(len(pattern_list)):\n",
    "        pattern = re.compile(pattern_list[x])     \n",
    "        if pattern.search(value):\n",
    "            #print(\"Yes\")\n",
    "            return pattern_list[x]\n",
    "        #else:\n",
    "        #    print(\"No\")\n",
    "        #    return \"No\"\n",
    "    return \"OTHERS\"\n",
    "\n",
    "func_FindTxnCategory = F.udf(findTxnCategory,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(findTxnCategory(\"MY IRCTC MONEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.withColumn(\"TXN_CATEGORY\",func_FindTxnCategory(\"Narration\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.select(\"TXN_CATEGORY\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.groupBy(\"TXN_CATEGORY\").count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.select()\n",
    "\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = (df1.withColumnRenamed('Deposit Amt.', 'Deposit_Amt')\n",
    "       .withColumnRenamed('Withdrawal Amt.', 'Withdrawal_Amt')\n",
    "       .withColumnRenamed('Closing Balance', 'Closing_Bal')\n",
    "      )\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupBy(\"TXN_CATEGORY\").sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupBy(\"TXN_CATEGORY\").agg({\"Withdrawal_Amt\":\"sum\",\"Deposit_Amt\":\"sum\",\"Narration\":\"count\"}).filter(df2[\"TXN_CATEGORY\"] == 'OTHERS').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
